# Sign-Language-Detection-Using-LSTM

A project that will help us in facilitating E-Learning education with the help of computer acknowledgment of sign based communication for both general and Visually impaired students as well. 

The goal is to Detect Real time Sign language. In a general overview, how this project is gonna work is
We have collected a bunch of data , that is data of our hands, our body and our face, basically can be called as keypoints and saved as Numpy Arrays. 
Then we have trained a deep neural network using LSTM layers. Basically LSTM layers are stacked architecture that provides us multiple outputs, other than just a single value. So in this case we have multiple frames from which we will be predicting our action to detect rather than just a single frame.
Then we are integrating it all together and performing real time sign language detection using OpenCV.

In the times of Covid-19 everything has shifted to “E-Learning Education”.There has been a huge impact on Global Education and Statical data shows that 1.5 billion students are out of school. 
